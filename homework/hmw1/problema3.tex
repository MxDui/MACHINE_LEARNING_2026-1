\section*{3. [2.5 puntos] Función de pérdida esperada}

Dados los valores de una función de pérdida $L_{kj}$, el riesgo esperado

\begin{equation}
E[L] = \sum_{k} \sum_{j} \int_{R_j} L_{kj} p(x, \mathcal{C}_k) dx
\end{equation}

se minimiza si para cada $x$ escogemos la clase para minimizar la siguiente expresión (ya que $p(x)$ no contiene al parámetro de clase):

\begin{equation}
\arg\min_{k} \left( \sum_{k} L_{kj} p(C_k|x) p(x) \right) = \arg\min_{k} \left( \sum_{k} L_{kj} p(C_k|x) \right)
\end{equation}

Verifica que si $L_{kj} = 1 - I_{kj}$, donde $I_{kj}$ son los elementos de la matriz identidad, entonces la minimización anterior se reduce a escoger la clase $i$ con la probabilidad más grande $p(\mathcal{C}_i|x)$.

\textbf{Solución:}

Esta es la función de pérdida 0-1 estándar en problemas de clasificación. Procederemos paso a paso:

\textbf{1. Definición de la función de pérdida:}

Con $L_{kj} = 1 - I_{kj}$, donde $I_{kj}$ son los elementos de la matriz identidad, tenemos:
$$L_{kj} = \begin{cases}
0 & \text{si } k = j \text{ (clasificación correcta)} \\
1 & \text{si } k \neq j \text{ (clasificación incorrecta)}
\end{cases}$$

\textbf{2. Cálculo de la pérdida esperada para asignar a la clase $j$:}

La expresión a minimizar para cada $x$ es:
$$\sum_{k} L_{kj} p(\mathcal{C}_k|x)$$

Sustituyendo $L_{kj} = 1 - I_{kj}$:
\begin{align}
\sum_{k} L_{kj} p(\mathcal{C}_k|x) &= \sum_{k} (1 - I_{kj}) p(\mathcal{C}_k|x) \\
&= \sum_{k} p(\mathcal{C}_k|x) - \sum_{k} I_{kj} p(\mathcal{C}_k|x) \\
&= 1 - p(\mathcal{C}_j|x)
\end{align}

donde usamos que $\sum_{k} p(\mathcal{C}_k|x) = 1$ y $\sum_{k} I_{kj} p(\mathcal{C}_k|x) = p(\mathcal{C}_j|x)$.

\textbf{3. Minimización:}

Para minimizar el riesgo esperado, debemos encontrar:
$$\arg\min_{j} \left[ 1 - p(\mathcal{C}_j|x) \right]$$

Como el término constante $1$ no afecta la minimización:
$$\arg\min_{j} \left[ 1 - p(\mathcal{C}_j|x) \right] = \arg\min_{j} \left[ - p(\mathcal{C}_j|x) \right] = \arg\max_{j} p(\mathcal{C}_j|x)$$

\textbf{Conclusión:}

Con la función de pérdida 0-1, la regla de decisión óptima es elegir la clase $i$ con la probabilidad a posteriori más alta:
$$i^* = \arg\max_{j} p(\mathcal{C}_j|x)$$

Esta es la regla de decisión de Bayes para clasificación, que minimiza la probabilidad de error de clasificación.


