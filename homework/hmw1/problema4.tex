\section*{4. [2.5 puntos] Función de pérdida relajada}

En los ejercicios 1 y 2 obtuviste funciones indicadoras para evaluar la pertenencia o no de puntos a hipótesis concretas.

\begin{enumerate}
    \item[a)] Debes extender la función indicadora para crear una nueva función que no evalúe de manera estrictamente ``dura'' la pertenencia a la hipótesis sino que permita considerar puntos cercanos a la frontera de la hipótesis de manera penalizada.
    

    \textbf{Definición matemática para elipse}
    
    Para una hipótesis de elipse con parámetros $\boldsymbol{\theta} = \{h, k, a, b\}$, definimos la \textbf{distancia normalizada}:
    
    $$d(x, y; \boldsymbol{\theta}) = \sqrt{\frac{(x - h)^2}{a^2} + \frac{(y - k)^2}{b^2}}$$
    
    \textbf{Interpretación geométrica:}
    \begin{itemize}
        \item $d(x, y) = 1$: punto en la frontera de la elipse
        \item $d(x, y) < 1$: punto en el interior
        \item $d(x, y) > 1$: punto en el exterior
    \end{itemize}
    
    \textbf{Función de pérdida relajada por partes}
    
    Definimos la función de pérdida suave con parámetro de suavidad $\delta > 0$:
    
    $$L_{\text{soft}}(x, y; \boldsymbol{\theta}, \delta) = \begin{cases}
    0 & \text{si } d(x, y) \leq 1 \\
    \frac{d(x, y) - 1}{\delta} & \text{si } 1 < d(x, y) \leq 1 + \delta \\
    1 & \text{si } d(x, y) > 1 + \delta
    \end{cases}$$


    \textbf{Propiedades matemáticas:}
    \begin{enumerate}
        \item \textbf{Rango:} $L_{\text{soft}} \in [0, 1]$
        \item \textbf{Continuidad:} La función es continua en todo $\mathbb{R}^2$
        \item \textbf{Límite:} $\lim_{\delta \to 0^+} L_{\text{soft}}(x, y) = \mathbb{1}_{\{d(x,y) > 1\}}$
    \end{enumerate}
    
    
    \item[b)] Tú debes definir una manera de extender la frontera hasta cierta distancia máxima más allá de la frontera original. Por ejemplo: englobando a la hipótesis dentro de un círculo con cierto radio, o definiendo una distancia $\Delta d$ más allá de la frontera de la hipótesis.
    
        
    La extensión de la frontera crea una \textbf{zona de transición} alrededor de la hipótesis original donde la clasificación no es binaria sino gradual.
    
    \textbf{Definición formal de la extensión}
    
    Para una elipse con parámetros $\boldsymbol{\theta} = \{h, k, a, b\}$ y parámetro de extensión $\delta > 0$, definimos tres regiones:
    
    \begin{align}
    \mathcal{R}_{\text{interior}} &= \{(x, y) : d(x, y; \boldsymbol{\theta}) \leq 1\} \\
    \mathcal{R}_{\text{transición}} &= \{(x, y) : 1 < d(x, y; \boldsymbol{\theta}) \leq 1 + \delta\} \\
    \mathcal{R}_{\text{exterior}} &= \{(x, y) : d(x, y; \boldsymbol{\theta}) > 1 + \delta\}
    \end{align}
    
    \textbf{Interpretación geométrica de la extensión}
    
    La zona de transición $\mathcal{R}_{\text{transición}}$ forma una ``cáscara elíptica'' definida por:
    
    \textbf{Frontera interior:} $\frac{(x - h)^2}{a^2} + \frac{(y - k)^2}{b^2} = 1$
    
    \textbf{Frontera exterior:} $\frac{(x - h)^2}{(a\sqrt{1 + \delta})^2} + \frac{(y - k)^2}{(b\sqrt{1 + \delta})^2} = 1$
    
    \textbf{Elección del parámetro de extensión}
    
    El parámetro $\delta$ controla el ancho de la zona de transición:
    
    \begin{itemize}
        \item \textbf{$\delta$ pequeño ($\delta < 0.1$):} Transición muy estrecha, comportamiento casi binario
        \item \textbf{$\delta$ moderado ($0.1 \leq \delta \leq 1$):} Balance entre suavidad y precisión
        \item \textbf{$\delta$ grande ($\delta > 1$):} Transición muy gradual, alta tolerancia
    \end{itemize}
    
    \textbf{Criterio de selección:} $\delta$ puede elegirse mediante validación cruzada o como fracción del tamaño característico de la hipótesis (ej. $\delta = 0.1 \cdot \max(a, b)$).
    
    
    \item[c)] En la región donde extiendas la frontera la función de pérdida debe penalizar en lugar de evaluar a cero.
    
    
    En lugar de una penalización binaria (0 o 1), implementamos una penalización que crece monotónicamente con la distancia a la frontera original.
    
    \textbf{Función de penalización lineal}
    
    La función de pérdida relajada con penalización lineal es:
    
    $$L_{\text{relajada}}(x, y; \boldsymbol{\theta}, \delta) = \begin{cases}
    0 & \text{si } d(x, y) \leq 1 \\[0.5em]
    \frac{d(x, y) - 1}{\delta} & \text{si } 1 < d(x, y) \leq 1 + \delta \\[0.5em]
    1 & \text{si } d(x, y) > 1 + \delta
    \end{cases}$$
    
    
    \textbf{Región interior ($d \leq 1$):}
    $$L_{\text{relajada}}(x, y) = 0$$
    \textit{Interpretación:} Clasificación completamente correcta, sin penalización.
    
    \textbf{Zona de transición ($1 < d \leq 1 + \delta$):}
    $$L_{\text{relajada}}(x, y) = \frac{d - 1}{\delta} \in (0, 1)$$
    \textit{Interpretación:} Penalización proporcional a la distancia de la frontera.
    
    \textbf{Región exterior ($d > 1 + \delta$):}
    $$L_{\text{relajada}}(x, y) = 1$$
    \textit{Interpretación:} Penalización máxima para puntos claramente fuera de la hipótesis extendida.
    
    \textbf{Propiedades de la función de penalización}
    
    \textbf{Continuidad:} Verificamos que la función es continua en los puntos de transición:
    
    \textit{En $d = 1$:}
    $$\lim_{d \to 1^-} L(d) = 0, \quad \lim_{d \to 1^+} L(d) = \frac{1-1}{\delta} = 0$$
    
    \textit{En $d = 1 + \delta$:}
    $$\lim_{d \to (1+\delta)^-} L(d) = \frac{(1+\delta)-1}{\delta} = 1, \quad \lim_{d \to (1+\delta)^+} L(d) = 1$$
    
    \textbf{Monotonicidad:} En la zona de transición:
    $$\frac{dL}{dd} = \frac{1}{\delta} > 0$$
    
    \textbf{Interpretación probabilística}
    
    La función relajada puede interpretarse como la probabilidad de clasificación incorrecta:
    
    $$L_{\text{relajada}}(x, y) \approx P(\text{clasificación incorrecta} | \text{posición en zona de transición})$$
    
    donde la probabilidad aumenta linealmente con la distancia a la frontera.
    
    
\end{enumerate}