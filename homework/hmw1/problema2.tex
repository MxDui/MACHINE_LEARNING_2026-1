\section*{2. [2.5 puntos] Clases de hipótesis}

Para una clase de hipótesis de elipses $\mathcal{H}_{\text{eli}}$ donde una elipse con centro en la coordenada $(h, k)$ se describe con la siguiente ecuación:

\begin{equation}
\frac{(x - h)^2}{a^2} + \frac{(y - k)^2}{b^2} = 1
\end{equation}

donde $a > 0$ y $b > 0$ son los parámetros para los semiejes de la elipse.

\begin{enumerate}
    \item[a)] Usa esta ecuación para escribir una función indicadora para evaluar si un punto en 2D pertenece o no a una hipótesis de una elipse particular $h_{\boldsymbol{\theta}} \in \mathcal{H}_{\text{eli}}$, donde $\boldsymbol{\theta} = \{h, k, a, b\}$.
    
    \textbf{Solución:}
        
    La ecuación estándar de una elipse con centro en $(h, k)$ y semiejes $a$ y $b$ es:
    $$\frac{(x - h)^2}{a^2} + \frac{(y - k)^2}{b^2} = 1$$
    
    Esta ecuación define la frontera de la elipse. Para la función indicadora, generalizo para incluir lo anterior:
    
    \textbf{Criterio de pertenencia}
    
    Defino la distancia normalizada:
    $$d(x, y) = \frac{(x - h)^2}{a^2} + \frac{(y - k)^2}{b^2}$$
    
    La interpretación es:
    \begin{itemize}
        \item Si $d(x, y) < 1$: el punto está dentro de la elipse
        \item Si $d(x, y) = 1$: el punto está sobre la elipse
        \item Si $d(x, y) > 1$: el punto está fuera de la elipse
    \end{itemize}
    
    \textbf{Función indicadora:}
    
    Para clasificación binaria, considero que un punto pertenece a la clase positiva si está dentro o sobre la elipse:
    
    $$h_{\boldsymbol{\theta}}(x,y) = \begin{cases}
    1 & \text{si } \frac{(x - h)^2}{a^2} + \frac{(y - k)^2}{b^2} \leq 1 \\
    0 & \text{en caso contrario}
    \end{cases}$$
    
    La función indicadora $h_{\boldsymbol{\theta}}: \mathbb{R}^2 \rightarrow \{0, 1\}$ divide el plano en dos regiones: el interior (incluyendo la frontera) de la elipse y el exterior.
    
    
    \item[b)] Escribe a manera de pseudocódigo un algoritmo para encontrar los parámetros $\boldsymbol{\theta}' = \{h', k', a', b'\}$ de la elipse más pequeña que sólo permite un error menor o igual a un umbral $\alpha$ (relativamente pequeño; por ejemplo, 10\%) de clasificaciones incorrectas (para una de dos clases) del total de puntos $\mathcal{X} = \{(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)\}$.
    
    \textbf{Solución:}
    
    \textbf{Formulación del problema}
    
    Buscamos la elipse más pequeña (en área) que clasifique correctamente al menos $(1-\alpha) \cdot n$ puntos, donde $n = |\mathcal{X}|$.
    
    \textbf{Definición matemática:} Minimizar $\pi a' b'$ (área de la elipse) sujeto a:
    $$\sum_{i=1}^{n} \mathbb{1}_{\{h_{\boldsymbol{\theta}'}(x_i, y_i) \neq y_i\}} \leq \lfloor \alpha \cdot n \rfloor$$
    
    \textbf{Estrategia de escalamiento}
    
    La idea es:
    \begin{enumerate}
        \item Estimar la forma y orientación de la elipse usando la clase positiva
        \item Encontrar la escala mínima que respete el presupuesto de error
    \end{enumerate}
    
    \textbf{Algoritmo paso a paso}
    
    \begin{algorithm}[H]
    \caption{ElipseMinima - Encontrar elipse mínima con umbral de error $\alphavar$}
    \begin{algorithmic}[1]
    \Require $\mathcal{X} = \{(x_i, y_i)\}_{i=1}^n$, $\mathcal{Y} = \{y_i\}_{i=1}^n \subseteq \{-1, +1\}$, $\alphavar \in (0, 1)$
    \Ensure $\boldsymbol{\theta}' = \{h', k', a', b'\}$
    \State \Comment{Separación por clases}
    \State $\mathcal{X}^+ \gets \{(x_i, y_i) : y_i = +1\}$
    \State $\mathcal{X}^- \gets \{(x_i, y_i) : y_i = -1\}$
    \State $n^+ \gets |\mathcal{X}^+|$, $n^- \gets |\mathcal{X}^-|$
    \State $\text{max\_errores} \gets \lfloor \alphavar \cdot n \rfloor$ \Comment{$\alphavar$ es hiperparámetro a validar}
    \State
    \State \Comment{Estimación del centro}
    \State $h' \gets \frac{1}{n^+} \sum_{(x,y) \in \mathcal{X}^+} x$
    \State $k' \gets \frac{1}{n^+} \sum_{(x,y) \in \mathcal{X}^+} y$
    \State
    \State \Comment{Estimación de la forma base}
    \State $\epsilon \gets 1 \times 10^{-9}$
    \State $a_0 \gets \sqrt{\frac{1}{n^+} \sum_{(x,y) \in \mathcal{X}^+} (x - h')^2} + \epsilon$
    \State $b_0 \gets \sqrt{\frac{1}{n^+} \sum_{(x,y) \in \mathcal{X}^+} (y - k')^2} + \epsilon$
    \State
    \State \Comment{Cálculo de distancias normalizadas}
    \For{cada punto $(x_i, y_i) \in \mathcal{X}$}
        \State $d_i \gets \sqrt{\frac{(x_i - h')^2}{a_0^2} + \frac{(y_i - k')^2}{b_0^2}}$
    \EndFor
    \State
    \State \Comment{Búsqueda de la escala óptima por búsqueda binaria}
    \State $\mathcal{S} \gets $ valores únicos ordenados de $\{d_i : i = 1, \ldots, n\}$
    \State $\ell \gets 1$ \Comment{límite inferior de escala}
    \State $r \gets \max \mathcal{S}$ \Comment{límite superior de escala}
    \State $s^* \gets r$
    \While{$\ell \leq r$}
        \State $m \gets (\ell + r)/2$
        \State $\text{errores} \gets$ errores\_con\_escala($\{d_i\}$, $\{y_i\}$, $m$)
        \If{$\text{errores} \leq \text{max\_errores}$}
            \State $s^* \gets m$; $r \gets m - \varepsilon$ \Comment{buscamos escala más pequeña}
        \Else
            \State $\ell \gets m + \varepsilon$
        \EndIf
    \EndWhile
    \State
    \State \Comment{Parámetros finales}
    \State $a' \gets a_0 \cdot s^*$
    \State $b' \gets b_0 \cdot s^*$
    \State \Return $\boldsymbol{\theta}' = \{h', k', a', b'\}$
    \end{algorithmic}
    \end{algorithm}
    
    
    \item[c)] Ahora encuentra también a manera de pseudocódigo los parámetros del elipse más grande que no introduce nuevos errores. Puedes partir de los parámetros $\boldsymbol{\theta}'$ del inciso anterior.
    
    \textbf{Solución:}
        
    Dada la elipse mínima $\boldsymbol{\theta}' = \{h', k', a', b'\}$, buscamos la elipse máxima $\boldsymbol{\theta}'' = \{h', k', a'', b''\}$ tal que:
    
    $$\text{errores}(\boldsymbol{\theta}'') = \text{errores}(\boldsymbol{\theta}')$$
    
    Es decir, no introducimos errores adicionales.
    
    \textbf{Restricción geométrica}
    
    Para no introducir nuevos errores, la elipse expandida no debe incluir puntos negativos que estaban correctamente clasificados como negativos.
    
    \textbf{Criterio} Si $(x_i, y_i) \in \mathcal{X}^-$ y está correctamente clasificado por $\boldsymbol{\theta}'$, entonces:
    $$\frac{(x_i - h')^2}{(a')^2} + \frac{(y_i - k')^2}{(b')^2} > 1$$
    
    \textbf{Factor de expansión}
    
    Si escalamos uniformemente: $a'' = s \cdot a'$ y $b'' = s \cdot b'$ con $s \geq 1$, entonces la nueva distancia normalizada para el punto $(x_i, y_i)$ es:
    
    $$d_i^{(s)} = \sqrt{\frac{(x_i - h')^2}{(s \cdot a')^2} + \frac{(y_i - k')^2}{(s \cdot b')^2}} = \frac{d_i^{(\text{original})}}{s}$$
    
    \textbf{Algoritmo de expansión}
    
    \begin{algorithm}[H]
    \caption{ElipseMaxima - Encontrar elipse máxima sin nuevos errores}
    \begin{algorithmic}[1]
    \Require $\boldsymbol{\theta}' = \{h', k', a', b'\}$, $\mathcal{X}$, $\mathcal{Y}$
    \Ensure $\boldsymbol{\theta}'' = \{h', k', a'', b''\}$
    \State \Comment{Calcular distancias originales}
    \For{cada punto $(x_i, y_i) \in \mathcal{X}$}
        \State $d_i^{(\text{original})} \gets \sqrt{\frac{(x_i - h')^2}{(a')^2} + \frac{(y_i - k')^2}{(b')^2}}$
    \EndFor
    \State
    \State \Comment{Identificar puntos negativos externos}
    \State $\mathcal{N} \gets \{i : y_i = -1 \text{ y } d_i^{(\text{original})} > 1\}$
    \State
    \State \Comment{Calcular factor de expansión máximo (sin introducir nuevos errores)}
    \If{$\mathcal{N} \neq \emptyset$}
        \State $\delta \gets 1 \times 10^{-6}$
        \State $s_{\max} \gets \min_{i \in \mathcal{N}} d_i^{(\text{original})} - \delta$
        \State $s_{\max} \gets \max(s_{\max}, 1.0)$
    \Else
        \State $s_{\max} \gets 1.0$
    \EndIf
    \State
    \State \Comment{Parámetros de la elipse máxima}
    \State $a'' \gets s_{\max} \cdot a'$
    \State $b'' \gets s_{\max} \cdot b'$
    \State
    \State \Comment{Verificación final}
    \State $\text{errores\_original} \gets $ contar\_errores($\mathcal{X}$, $\mathcal{Y}$, $\boldsymbol{\theta}'$)
    \State $\text{errores\_expandida} \gets $ contar\_errores($\mathcal{X}$, $\mathcal{Y}$, $\{h', k', a'', b''\}$)
    \While{$\text{errores\_expandida} > \text{errores\_original}$}
        \State $s_{\max} \gets s_{\max} \times 0.999$
        \State $a'' \gets s_{\max} \cdot a'$
        \State $b'' \gets s_{\max} \cdot b'$
        \State $\text{errores\_expandida} \gets $ contar\_errores($\mathcal{X}$, $\mathcal{Y}$, $\{h', k', a'', b''\}$)
    \EndWhile
    \State
    \State \Return $\boldsymbol{\theta}'' = \{h', k', a'', b''\}$
    \end{algorithmic}
    \end{algorithm}

   
    \item[d)] Finalmente propón como hipótesis para la función indicadora un elipse que esté entre ambos (de los incisos b y c), por ejemplo a la mitad del camino paramétricamente hablando.
    
    \textbf{Solución:}
        
    La elipse mínima $\boldsymbol{\theta}'$ minimiza el error de entrenamiento pero puede ser muy conservadora (alto sesgo). La elipse máxima $\boldsymbol{\theta}''$ maximiza el margen pero puede ser muy permisiva. Una interpolación puede balancear estos extremos.
    
    \textbf{Interpolación lineal}
    
    Para un parámetro de interpolación $\lambda \in [0, 1]$, definimos:
    
    \begin{align}
    h_{\text{final}} &= h' \quad \text{(el centro no cambia)} \\
    k_{\text{final}} &= k' \quad \text{(el centro no cambia)} \\
    a_{\text{final}} &= (1 - \lambda) a' + \lambda a'' \\
    b_{\text{final}} &= (1 - \lambda) b' + \lambda b''
    \end{align}
    
    \textbf{Caso especial ($\lambda = 0.5$):} Para el punto medio:
    \begin{align}
    a_{\text{final}} &= \frac{a' + a''}{2} \\
    b_{\text{final}} &= \frac{b' + b''}{2}
    \end{align}
    
    \textbf{Función indicadora interpolada}
    
    $$h_{\text{final}}(x,y) = \begin{cases}
    1 & \text{si } \frac{(x - h')^2}{a_{\text{final}}^2} + \frac{(y - k')^2}{b_{\text{final}}^2} \leq 1 \\
    0 & \text{en caso contrario}
    \end{cases}$$
    
    \textbf{Interpretación geométrica}
    
    La elipse interpolada tiene:
    \begin{itemize}
        \item \textbf{Área:} $\pi a_{\text{final}} b_{\text{final}} = \pi \cdot \frac{a' + a''}{2} \cdot \frac{b' + b''}{2}$
        \item \textbf{Error esperado:} Entre el error mínimo y el error de la elipse máxima
        \item \textbf{Generalización:} Potencialmente mejor que los extremos
    \end{itemize}
    
    \textbf{Validación}
    
    Para validar la elección de $\lambda$, se puede:
    \begin{enumerate}
        \item Usar validación cruzada para seleccionar $\lambda^* \in [0, 1]$
        \item Evaluar el error en un conjunto de prueba
        \item Comparar con $\lambda = 0$ (elipse mínima) y $\lambda = 1$ (elipse máxima)
    \end{enumerate}
    
\end{enumerate}